PDF-RAG-Query
Overview
PDF-RAG-Query is a Streamlit-based web application designed to process PDF documents and enable intelligent querying using Retrieval-Augmented Generation (RAG). It leverages LangChain, Chroma vector store, and Google Gemini to extract text and tables from PDFs, store embeddings, and provide accurate answers to user queries based on document content.
Features

PDF Upload and Processing: Upload multiple PDF files, extract text and tables, and split content into chunks for efficient processing.
Vector Store: Use Chroma to store document embeddings for fast similarity search.
Query Interface: Ask questions about uploaded documents, with answers generated by Google Gemini and source attribution.
Document Management: View, filter, and delete uploaded documents.
System Status: Monitor vector store statistics and system configuration details.

Prerequisites

Python 3.8 or higher
A valid Google API key for Gemini LLM (set in .env file)
Sufficient disk space for document storage and vector store

Installation

Clone the Repository
git clone https://github.com/VirajSawad1021/PDF-RAG-Query.git
cd PDF-RAG-Query


Create a Virtual Environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate


Install Dependencies
pip install -r requirements.txt


Set Up Environment VariablesCreate a .env file in the project root with your Google API key:
GOOGLE_API_KEY=your-google-api-key


Run the Application
streamlit run app.py



Usage

Upload Documents: Go to the "Upload Documents" page to upload PDFs. Customize chunk size and overlap as needed.
Query Documents: Use the "Query Documents" page to ask questions, with options to filter by specific documents or search all.
Document Management: Manage uploaded documents (view or delete) on the "Document Management" page.
System Status: Check system metrics and configuration on the "System Status" page.

Project Structure
PDF-RAG-Query/
├── app.py                  # Main Streamlit application
├── pdf_processor.py        # PDF processing and table extraction
├── vector_store.py         # Vector store management with Chroma
├── llm_service.py          # LLM integration with Google Gemini
├── config.py               # Configuration settings
├── requirements.txt        # Project dependencies
├── .env                    # Environment variables (not tracked)
├── .gitignore              # Git ignore file
├── uploads/                # Temporary storage for uploaded PDFs
├── data/                   # Storage for vector store
└── README.md               # This file

Configuration
The config.py file allows customization of:

Chunk Size and Overlap: Adjust how PDFs are split into chunks.
Directories: Define paths for uploads and vector store.
Embeddings Model: Uses all-MiniLM-L6-v2 for document embeddings.
API Key: Google API key for LLM access.

Dependencies
Key dependencies (see requirements.txt for the full list):

Streamlit
LangChain and related packages
pdfplumber for PDF processing
sentence-transformers for embeddings
pydantic for settings management

Notes

The .env file should not be committed to version control (excluded in .gitignore).
The maximum PDF file size is 10MB by default (configurable in config.py).
Use the "Document Management" page to clear the vector store if needed.

Contributing
Contributions are welcome! Please submit pull requests or open issues for bugs, features, or improvements.
License
This project is licensed under the MIT License.
